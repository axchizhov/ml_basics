{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed926e84-b1ed-467b-a5b8-e576629fc3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd035bb6d9f4d5c9620f8e51daf6400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8ab856444b4855bf0446cde71cce43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80dbfd6def241cda5e529e04c0293e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b8d30172fb4b88865f3d3e4847d479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b90764f2f94a7aba93d408ae3a62ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949e474690e4479eac616df136193505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd718d6f54fd4399873e40ee0e589975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284dd36dcd1d440eb49ff4d7d59e6715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [04:22<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 2.4152, Val Accuracy: 0.1031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "\n",
    "\n",
    "transform = ResNet18_Weights.IMAGENET1K_V1.transforms()\n",
    "\n",
    "cifar10 = datasets.load_dataset(\"cifar10\")\n",
    "train_val_split = cifar10[\"train\"].train_test_split(test_size=0.1, stratify_by_column=\"label\")\n",
    "cifar10 = datasets.DatasetDict(\n",
    "    {\"train\": train_val_split[\"train\"], \"val\": train_val_split[\"test\"], \"test\": cifar10[\"test\"]}\n",
    ")\n",
    "cifar10 = cifar10.rename_column(\"img\", \"image\")\n",
    "cifar10 = cifar10.map(lambda sample: {\"pixel_values\": transform(sample[\"image\"])})\n",
    "cifar10.set_format(\"pt\", columns=[\"pixel_values\"], output_all_columns=True)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for example in examples:\n",
    "        images.append(example[\"pixel_values\"])\n",
    "        labels.append(example[\"label\"])\n",
    "\n",
    "    pixel_values = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "def get_data_loader(dataset):\n",
    "    batch_size = 32\n",
    "\n",
    "    loader = {}\n",
    "    for split, data in dataset.items():\n",
    "        loader[split] = torch.utils.data.DataLoader(data, collate_fn=collate_fn, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "# Load pretrained ResNet18\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.eval()\n",
    "\n",
    "# Modify the final layer to match CIFAR-10 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_ftrs, 10)\n",
    "\n",
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(val_loader):\n",
    "            inputs = batch[\"pixel_values\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_pred_class = outputs.argmax(dim=1)\n",
    "            test_accuracy += (y_pred_class == labels).sum().item() / len(y_pred_class)\n",
    "\n",
    "    test_loss = test_loss / len(val_loader)\n",
    "    test_accuracy = test_accuracy / len(val_loader)\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "cifar_loader = get_data_loader(cifar10)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "test_loss, test_accuracy = validate(model, criterion, cifar_loader[\"val\"], \"cpu\")\n",
    "\n",
    "print(f\"Val Loss: {test_loss:.4f}, Val Accuracy: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
