{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c3a024-da7e-4605-b6c0-70c2f6982cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Init\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "\n",
    "torch.set_printoptions(sci_mode=False, linewidth=120)\n",
    "\n",
    "\n",
    "def setup_seed(seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "\n",
    "setup_seed(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7565515-b164-488b-ae93-7b619355a9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define datasets and loaders\n",
    "\n",
    "def get_datasets():\n",
    "    setup_seed(42)\n",
    "\n",
    "    image_size = 28\n",
    "    transform = T.Compose([T.Resize(image_size), T.ToTensor(), T.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "    cifar10 = datasets.load_dataset(\"cifar10\")\n",
    "    train_eval_split = cifar10[\"train\"].train_test_split(test_size=0.1, stratify_by_column=\"label\")\n",
    "    cifar10 = datasets.DatasetDict(\n",
    "        {\"train\": train_eval_split[\"train\"], \"eval\": train_eval_split[\"test\"], \"test\": cifar10[\"test\"]}\n",
    "    )\n",
    "    cifar10 = cifar10.rename_column(\"img\", \"image\")\n",
    "    cifar10 = cifar10.cast_column(\"image\", datasets.Image(mode=\"L\"))\n",
    "    cifar10 = cifar10.map(lambda sample: {\"pixel_values\": transform(sample[\"image\"])})\n",
    "    cifar10.set_format(\"pt\", columns=[\"pixel_values\"], output_all_columns=True)\n",
    "\n",
    "    mnist = datasets.load_dataset(\"mnist\")\n",
    "    train_eval_split = mnist[\"train\"].train_test_split(test_size=0.1, stratify_by_column=\"label\")\n",
    "    mnist = datasets.DatasetDict(\n",
    "        {\"train\": train_eval_split[\"train\"], \"eval\": train_eval_split[\"test\"], \"test\": mnist[\"test\"]}\n",
    "    )\n",
    "    mnist = mnist.map(lambda sample: {\"pixel_values\": transform(sample[\"image\"])})\n",
    "    mnist.set_format(\"pt\", columns=[\"pixel_values\"], output_all_columns=True)\n",
    "\n",
    "    return cifar10, mnist\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for example in examples:\n",
    "        images.append(example[\"pixel_values\"])\n",
    "        labels.append(example[\"label\"])\n",
    "\n",
    "    pixel_values = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "def get_data_loader(dataset):\n",
    "    batch_size = 32\n",
    "\n",
    "    loader = {}\n",
    "    for split, data in dataset.items():\n",
    "        loader[split] = torch.utils.data.DataLoader(data, collate_fn=collate_fn, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69c2aa-7a4a-4551-8fcf-ba1354a7b331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/citizen2/Documents/norm_research/.venv/lib/python3.10/site-packages/datasets/load.py:1491: FutureWarning: The repository for mnist contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mnist\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# %% Load datasets\n",
    "\n",
    "cifar10, mnist = get_datasets()\n",
    "\n",
    "cifar10_loaders = get_data_loader(cifar10)\n",
    "mnist_loaders = get_data_loader(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30728bdf-b5ac-48ff-a5f2-60d444b056cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Train/eval loops\n",
    "\n",
    "def train_one_epoch(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "\n",
    "    for batch in tqdm(train_loader):\n",
    "        inputs = batch[\"pixel_values\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        y_pred_class = outputs.argmax(dim=1)\n",
    "        batch_accuracy = (y_pred_class == labels).sum().item() / len(y_pred_class)\n",
    "        train_accuracy += batch_accuracy\n",
    "\n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = train_accuracy / len(train_loader)\n",
    "\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "def validate(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(val_loader):\n",
    "            inputs = batch[\"pixel_values\"]\n",
    "            labels = batch[\"labels\"]\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_pred_class = outputs.argmax(dim=1)\n",
    "            test_accuracy += (y_pred_class == labels).sum().item() / len(y_pred_class)\n",
    "\n",
    "    test_loss = test_loss / len(val_loader)\n",
    "    test_accuracy = test_accuracy / len(val_loader)\n",
    "\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "def train_model(model, loaders: dict):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 5\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_accuracy = train_one_epoch(model, criterion, optimizer, loaders[\"train\"], device)\n",
    "\n",
    "        val_loss, val_accuracy = validate(model, criterion, loaders[\"eval\"], device)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d37d2bd-4f38-4cd1-af15-99103c574622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [07:30<00:00,  3.12it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5575, Train Accuracy: 0.4458\n",
      "Val Loss: 1.3916, Val Accuracy: 0.5165\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [07:04<00:00,  3.32it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 14.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1894, Train Accuracy: 0.5830\n",
      "Val Loss: 1.2501, Val Accuracy: 0.5657\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [07:05<00:00,  3.31it/s]\n",
      "100%|██████████| 157/157 [00:14<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9948, Train Accuracy: 0.6516\n",
      "Val Loss: 1.0830, Val Accuracy: 0.6320\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [08:21<00:00,  2.81it/s]\n",
      "100%|██████████| 157/157 [00:12<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8328, Train Accuracy: 0.7118\n",
      "Val Loss: 1.0859, Val Accuracy: 0.6445\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1407/1407 [08:11<00:00,  2.86it/s]\n",
      "100%|██████████| 157/157 [00:10<00:00, 14.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6947, Train Accuracy: 0.7595\n",
      "Val Loss: 1.1716, Val Accuracy: 0.6399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Train the base model (on cifar10)\n",
    "\n",
    "model_base_cifar = torchvision.models.resnet18(num_classes=10)\n",
    "# Make the model take images with 1 channel\n",
    "model_base_cifar.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_base_cifar = train_model(model_base_cifar, cifar10_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5724f9e-7b96-459d-848a-2fd56535af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [09:25<00:00,  2.98it/s]\n",
      "100%|██████████| 188/188 [00:12<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1585, Train Accuracy: 0.9533\n",
      "Val Loss: 0.0596, Val Accuracy: 0.9819\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [08:55<00:00,  3.15it/s]\n",
      "100%|██████████| 188/188 [00:11<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0696, Train Accuracy: 0.9802\n",
      "Val Loss: 0.0629, Val Accuracy: 0.9820\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [08:39<00:00,  3.25it/s]\n",
      "100%|██████████| 188/188 [00:11<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0561, Train Accuracy: 0.9843\n",
      "Val Loss: 0.0682, Val Accuracy: 0.9822\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [08:35<00:00,  3.27it/s]\n",
      "100%|██████████| 188/188 [00:11<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0420, Train Accuracy: 0.9873\n",
      "Val Loss: 0.0865, Val Accuracy: 0.9764\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [09:54<00:00,  2.84it/s]\n",
      "100%|██████████| 188/188 [00:15<00:00, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0339, Train Accuracy: 0.9895\n",
      "Val Loss: 0.0411, Val Accuracy: 0.9904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %% Train the base model (on mnist)\n",
    "\n",
    "model_base_mnist = torchvision.models.resnet18(num_classes=10)\n",
    "model_base_mnist.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_base_mnist = train_model(model_base_mnist, mnist_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab0cfb-b6f4-4749-b717-60bb6afe9b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1688/1688 [10:44<00:00,  2.62it/s]\n",
      "100%|██████████| 188/188 [00:14<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0315, Train Accuracy: 0.9909\n",
      "Val Loss: 0.0497, Val Accuracy: 0.9882\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1069/1688 [06:45<03:54,  2.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m/Users/citizen2/Documents/norm_research/experiment1.py:13\u001b[0m\n\u001b[1;32m      9\u001b[0m     param\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     11\u001b[0m model_cifar_to_mnist\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mLinear(in_features\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, out_features\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m model_base_mnist \u001b[39m=\u001b[39m train_model(model_base_mnist, mnist_loaders)\n",
      "File \u001b[1;32m/Users/citizen2/Documents/norm_research/experiment1.py:69\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     67\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train_one_epoch(model, criterion, optimizer, loaders[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m], device)\n\u001b[1;32m     71\u001b[0m     val_loss, val_accuracy \u001b[39m=\u001b[39m validate(model, criterion, loaders[\u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m], device)\n\u001b[1;32m     73\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Train Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtrain_accuracy\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m/Users/citizen2/Documents/norm_research/experiment1.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     23\u001b[0m y_pred_class \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m batch_accuracy \u001b[39m=\u001b[39m (y_pred_class \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_pred_class)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[1;32m    169\u001b[0m         exp_avgs,\n\u001b[1;32m    170\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    172\u001b[0m         state_steps,\n\u001b[1;32m    173\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    175\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    176\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    177\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    182\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    183\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    184\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    185\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m func(params,\n\u001b[1;32m    317\u001b[0m      grads,\n\u001b[1;32m    318\u001b[0m      exp_avgs,\n\u001b[1;32m    319\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    321\u001b[0m      state_steps,\n\u001b[1;32m    322\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    323\u001b[0m      has_complex\u001b[39m=\u001b[39;49mhas_complex,\n\u001b[1;32m    324\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    325\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    326\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    327\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    328\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    329\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    330\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    331\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    332\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    333\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    441\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% Fine-tune the model on new dataset (mnist)\n",
    "\n",
    "import copy\n",
    "\n",
    "model_cifar_to_mnist = copy.deepcopy(model_base_cifar)\n",
    "\n",
    "# Prepare model for fine tuning\n",
    "\n",
    "for param in model_cifar_to_mnist.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_cifar_to_mnist.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "model_base_mnist = train_model(model_base_mnist, mnist_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/citizen2/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:04<00:00, 10.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39;49mparams()\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "model.fc.params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39;49mparams\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "model.fc.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x178355af0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
       "         [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
       "         [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
       "         ...,\n",
       "         [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
       "         [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
       "         [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([    -0.0026,      0.0030,      0.0007,     -0.0269,      0.0064,      0.0133,     -0.0112,      0.0206,\n",
       "             -0.0036,     -0.0123,     -0.0126,     -0.0072,     -0.0193,     -0.0250,     -0.0119,     -0.0083,\n",
       "             -0.0096,     -0.0167,      0.0092,     -0.0154,      0.0071,      0.0307,      0.0132,     -0.0078,\n",
       "              0.0047,      0.0112,      0.0159,     -0.0167,     -0.0010,     -0.0037,      0.0065,     -0.0120,\n",
       "              0.0090,     -0.0008,      0.0089,     -0.0263,     -0.0146,      0.0029,      0.0030,     -0.0191,\n",
       "             -0.0048,      0.0138,      0.0099,     -0.0184,      0.0197,      0.0017,      0.0124,     -0.0056,\n",
       "             -0.0106,      0.0004,      0.0043,     -0.0133,      0.0207,      0.0170,      0.0028,      0.0007,\n",
       "              0.0132,      0.0032,      0.0105,      0.0165,      0.0009,      0.0039,     -0.0057,      0.0194,\n",
       "              0.0075,      0.0134,     -0.0132,     -0.0100,      0.0072,     -0.0023,     -0.0189,      0.0125,\n",
       "              0.0020,      0.0074,     -0.0097,      0.0202,      0.0077,      0.0185,      0.0157,      0.0186,\n",
       "             -0.0069,      0.0171,      0.0091,     -0.0389,     -0.0241,     -0.0069,     -0.0116,      0.0079,\n",
       "              0.0018,      0.0285,     -0.0194,     -0.0163,      0.0105,     -0.0130,     -0.0084,     -0.0292,\n",
       "             -0.0025,     -0.0087,     -0.0164,     -0.0093,     -0.0159,     -0.0263,     -0.0011,      0.0226,\n",
       "              0.0021,     -0.0232,     -0.0141,     -0.0056,     -0.0201,     -0.0303,     -0.0496,      0.0233,\n",
       "              0.0150,     -0.0078,     -0.0039,     -0.0376,     -0.0242,     -0.0102,     -0.0077,     -0.0041,\n",
       "             -0.0030,     -0.0062,     -0.0121,     -0.0070,     -0.0039,     -0.0170,     -0.0246,      0.0055,\n",
       "             -0.0083,     -0.0071,     -0.0240,     -0.0064,      0.0007,      0.0053,     -0.0222,     -0.0270,\n",
       "             -0.0180,     -0.0164,      0.0021,     -0.0161,     -0.0161,      0.0066,     -0.0200,      0.0064,\n",
       "             -0.0126,     -0.0076,      0.0114,     -0.0451,     -0.0092,     -0.0156,     -0.0136,     -0.0014,\n",
       "             -0.0195,      0.0207,     -0.0105,      0.0063,      0.0083,     -0.0108,     -0.0189,      0.0059,\n",
       "             -0.0020,      0.0324,      0.0406,     -0.0000,      0.0109,     -0.0165,     -0.0005,     -0.0229,\n",
       "              0.0046,     -0.0048,      0.0102,      0.0180,      0.0048,      0.0062,      0.0144,     -0.0121,\n",
       "             -0.0087,      0.0019,      0.0147,      0.0125,      0.0071,     -0.0042,      0.0120,     -0.0202,\n",
       "              0.0099,      0.0140,     -0.0010,      0.0057,      0.0014,      0.0006,     -0.0006,      0.0244,\n",
       "              0.0231,     -0.0146,      0.0112,      0.0346,      0.0169,      0.0043,     -0.0256,      0.0123,\n",
       "             -0.0258,      0.0085,      0.0204,      0.0226,      0.0230,      0.0088,     -0.0139,      0.0039,\n",
       "             -0.0093,      0.0232,     -0.0149,      0.0069,      0.0050,     -0.0173,      0.0010,     -0.0102,\n",
       "             -0.0097,      0.0345,      0.0061,      0.0116,     -0.0205,     -0.0220,      0.0053,      0.0341,\n",
       "             -0.0058,      0.0294,     -0.0088,     -0.0053,     -0.0191,      0.0304,      0.0184,     -0.0212,\n",
       "              0.0184,      0.0138,      0.0178,     -0.0045,      0.0359,      0.0218,      0.0109,      0.0403,\n",
       "             -0.0020,     -0.0030,      0.0093,     -0.0163,      0.0010,      0.0187,     -0.0166,      0.0150,\n",
       "             -0.0037,     -0.0077,     -0.0000,      0.0040,     -0.0096,     -0.0168,      0.0001,     -0.0064,\n",
       "              0.0083,      0.0048,     -0.0011,      0.0049,      0.0173,      0.0039,     -0.0078,      0.0161,\n",
       "              0.0099,     -0.0101,      0.0209,     -0.0063,     -0.0231,      0.0012,      0.0225,     -0.0067,\n",
       "              0.0183,      0.0146,     -0.0117,     -0.0143,      0.0130,     -0.0097,     -0.0062,      0.0132,\n",
       "              0.0068,      0.0464,     -0.0280,     -0.0151,      0.0287,      0.0092,     -0.0054,     -0.0060,\n",
       "             -0.0072,     -0.0092,      0.0019,     -0.0031,     -0.0084,     -0.0168,      0.0041,      0.0062,\n",
       "             -0.0012,     -0.0129,      0.0036,      0.0110,     -0.0133,      0.0026,      0.0090,      0.0065,\n",
       "             -0.0120,      0.0171,      0.0179,     -0.0106,     -0.0270,     -0.0136,     -0.0097,     -0.0021,\n",
       "              0.0354,      0.0184,      0.0267,     -0.0011,     -0.0034,     -0.0049,      0.0134,     -0.0139,\n",
       "             -0.0196,     -0.0233,     -0.0378,     -0.0146,     -0.0213,     -0.0310,     -0.0308,      0.0019,\n",
       "              0.0029,     -0.0212,      0.0104,     -0.0113,     -0.0043,      0.0226,     -0.0129,     -0.0110,\n",
       "              0.0123,     -0.0201,     -0.0218,     -0.0068,     -0.0105,     -0.0263,     -0.0100,     -0.0130,\n",
       "             -0.0025,     -0.0071,      0.0180,     -0.0064,      0.0079,     -0.0123,      0.0098,      0.0027,\n",
       "             -0.0215,      0.0028,     -0.0092,     -0.0175,     -0.0017,     -0.0146,      0.0044,      0.0344,\n",
       "              0.0127,      0.0309,      0.0013,     -0.0001,     -0.0023,     -0.0038,     -0.0111,      0.0172,\n",
       "             -0.0068,     -0.0001,     -0.0089,     -0.0163,     -0.0045,      0.0113,     -0.0016,     -0.0088,\n",
       "             -0.0049,      0.0046,     -0.0109,      0.0129,     -0.0067,     -0.0026,      0.0028,      0.0112,\n",
       "             -0.0221,     -0.0039,     -0.0066,     -0.0188,     -0.0217,     -0.0007,     -0.0273,      0.0050,\n",
       "             -0.0207,     -0.0341,     -0.0224,     -0.0167,     -0.0279,     -0.0099,      0.0055,      0.0160,\n",
       "             -0.0149,      0.0035,      0.0090,     -0.0084,     -0.0375,      0.0207,     -0.0059,      0.0092,\n",
       "             -0.0203,     -0.0073,     -0.0017,     -0.0014,      0.0032,      0.0292,      0.0125,     -0.0201,\n",
       "              0.0212,     -0.0253,      0.0318,     -0.0011,     -0.0104,     -0.0234,      0.0146,      0.0212,\n",
       "              0.0165,     -0.0032,     -0.0204,     -0.0370,     -0.0087,      0.0055,      0.0011,      0.0022,\n",
       "              0.0030,     -0.0001,      0.0006,     -0.0037,      0.0054,     -0.0248,      0.0093,      0.0096,\n",
       "              0.0092,      0.0091,      0.0075,     -0.0119,      0.0214,      0.0279,      0.0147,     -0.0025,\n",
       "              0.0289,      0.0134,      0.0017,      0.0025,     -0.0213,     -0.0008,      0.0042,      0.0086,\n",
       "              0.0187,      0.0086,     -0.0088,      0.0175,     -0.0137,      0.0022,      0.0108,      0.0029,\n",
       "              0.0310,      0.0085,     -0.0142,     -0.0022,      0.0187,     -0.0129,      0.0404,     -0.0008,\n",
       "              0.0019,      0.0073,     -0.0265,     -0.0176,     -0.0241,      0.0030,     -0.0159,      0.0016,\n",
       "              0.0111,      0.0146,     -0.0082,     -0.0077,     -0.0185,     -0.0090,      0.0041,      0.0445,\n",
       "             -0.0237,     -0.0053,     -0.0195,      0.0033,      0.0055,     -0.0050,      0.0077,     -0.0033,\n",
       "             -0.0026,     -0.0111,      0.0239,      0.0181,     -0.0181,      0.0052,     -0.0136,      0.0194,\n",
       "              0.0110,      0.0269,     -0.0067,     -0.0009,     -0.0035,     -0.0197,     -0.0185,     -0.0008,\n",
       "             -0.0164,     -0.0159,     -0.0137,      0.0175,     -0.0011,     -0.0063,     -0.0111,      0.0132,\n",
       "             -0.0235,      0.0003,     -0.0004,      0.0238,     -0.0027,     -0.0222,      0.0134,      0.0104,\n",
       "             -0.0235,      0.0168,      0.0044,     -0.0132,     -0.0029,      0.0054,      0.0020,     -0.0007,\n",
       "             -0.0004,      0.0178,      0.0184,      0.0285,     -0.0338,     -0.0108,     -0.0124,     -0.0019,\n",
       "             -0.0016,      0.0173,     -0.0040,     -0.0152,     -0.0108,      0.0054,     -0.0003,      0.0003,\n",
       "             -0.0102,     -0.0040,     -0.0035,      0.0042,     -0.0015,      0.0132,      0.0076,      0.0002,\n",
       "              0.0030,      0.0086,     -0.0112,      0.0385,     -0.0262,     -0.0203,     -0.0064,      0.0219,\n",
       "             -0.0073,      0.0053,     -0.0117,      0.0084,      0.0029,     -0.0047,      0.0231,     -0.0076,\n",
       "              0.0028,     -0.0117,     -0.0044,      0.0118,     -0.0018,     -0.0123,     -0.0021,      0.0121,\n",
       "              0.0068,     -0.0002,     -0.0251,      0.0127,      0.0161,      0.0081,      0.0014,      0.0030,\n",
       "             -0.0141,      0.0198,     -0.0009,     -0.0184,      0.0078,      0.0153,     -0.0128,     -0.0090,\n",
       "              0.0180,      0.0249,      0.0178,      0.0089,     -0.0094,     -0.0014,      0.0129,      0.0090,\n",
       "              0.0167,     -0.0054,      0.0275,     -0.0318,     -0.0133,      0.0056,     -0.0133,     -0.0192,\n",
       "             -0.0133,      0.0042,      0.0302,     -0.0082,      0.0083,      0.0190,      0.0106,      0.0313,\n",
       "              0.0193,      0.0034,      0.0197,      0.0023,     -0.0196,      0.0201,     -0.0114,     -0.0076,\n",
       "              0.0151,     -0.0030,     -0.0093,     -0.0042,      0.0023,     -0.0051,     -0.0145,     -0.0277,\n",
       "             -0.0387,      0.0054,      0.0135,     -0.0013,      0.0375,      0.0015,      0.0240,     -0.0206,\n",
       "              0.0098,      0.0104,      0.0386,     -0.0119,     -0.0217,      0.0084,      0.0147,      0.0226,\n",
       "             -0.0038,      0.0156,     -0.0094,      0.0054,      0.0196,     -0.0112,      0.0152,      0.0055,\n",
       "              0.0230,      0.0293,     -0.0015,      0.0066,     -0.0319,     -0.0105,     -0.0045,      0.0319,\n",
       "              0.0137,      0.0136,      0.0071,     -0.0168,     -0.0255,      0.0198,      0.0267,     -0.0047,\n",
       "              0.0177,      0.0325,      0.0146,      0.0261,      0.0113,     -0.0022,      0.0352,     -0.0119,\n",
       "             -0.0187,     -0.0055,     -0.0071,     -0.0053,      0.0076,     -0.0185,     -0.0169,      0.0101,\n",
       "              0.0130,     -0.0018,      0.0007,     -0.0112,      0.0136,     -0.0182,     -0.0265,      0.0061,\n",
       "              0.0397,     -0.0143,      0.0180,     -0.0140,     -0.0188,     -0.0118,     -0.0164,      0.0090,\n",
       "             -0.0073,      0.0175,     -0.0007,      0.0102,      0.0238,      0.0081,      0.0080,      0.0119,\n",
       "              0.0062,     -0.0246,      0.0295,     -0.0142,     -0.0187,     -0.0141,      0.0080,     -0.0211,\n",
       "             -0.0276,     -0.0036,      0.0016,      0.0095,      0.0183,     -0.0024,      0.0012,     -0.0006,\n",
       "              0.0088,      0.0028,      0.0007,      0.0159,     -0.0070,      0.0025,     -0.0179,      0.0085,\n",
       "              0.0043,      0.0245,      0.0037,      0.0103,     -0.0134,      0.0005,      0.0103,      0.0152,\n",
       "              0.0399,     -0.0081,      0.0138,     -0.0066,      0.0066,     -0.0315,      0.0247,      0.0034,\n",
       "              0.0210,      0.0194,     -0.0209,      0.0071,      0.0104,      0.0000,     -0.0192,      0.0063,\n",
       "             -0.0002,      0.0089,     -0.0048,     -0.0145,      0.0032,      0.0073,      0.0207,     -0.0005,\n",
       "              0.0188,      0.0391,     -0.0271,     -0.0183,     -0.0199,     -0.0094,      0.0042,      0.0054,\n",
       "             -0.0047,     -0.0130,     -0.0245,     -0.0089,     -0.0146,      0.0026,     -0.0308,      0.0112,\n",
       "             -0.0068,     -0.0076,     -0.0093,      0.0015,     -0.0023,      0.0004,     -0.0108,      0.0088,\n",
       "             -0.0210,     -0.0080,     -0.0108,     -0.0065,     -0.0021,      0.0223,     -0.0192,      0.0041,\n",
       "              0.0008,      0.0017,     -0.0175,     -0.0132,     -0.0074,     -0.0018,      0.0013,     -0.0067,\n",
       "             -0.0071,      0.0063,     -0.0181,     -0.0095,     -0.0209,      0.0090,      0.0213,      0.0170,\n",
       "              0.0210,      0.0088,     -0.0098,     -0.0223,      0.0243,     -0.0112,     -0.0076,      0.0061,\n",
       "             -0.0207,     -0.0163,      0.0265,     -0.0148,      0.0187,      0.0255,      0.0241,      0.0048,\n",
       "              0.0233,      0.0004,      0.0252,      0.0171,      0.0178,      0.0247,      0.0090,      0.0024,\n",
       "              0.0261,     -0.0141,     -0.0005,      0.0009,      0.0212,      0.0048,     -0.0305,     -0.0075,\n",
       "             -0.0337,     -0.0289,      0.0157,      0.0062,     -0.0109,      0.0195,     -0.0162,      0.0090,\n",
       "              0.0092,     -0.0029,     -0.0109,      0.0108,      0.0488,     -0.0020,      0.0268,     -0.0049,\n",
       "              0.0135,     -0.0145,     -0.0276,      0.0061,      0.0048,      0.0022,     -0.0376,      0.0308,\n",
       "              0.0200,      0.0185,      0.0030,      0.0094,      0.0005,      0.0616,     -0.0086,     -0.0269,\n",
       "              0.0064,      0.0078,      0.0132,     -0.0017,      0.0209,      0.0099,      0.0088,      0.0148,\n",
       "              0.0033,      0.0036,      0.0287,     -0.0221,     -0.0072,      0.0104,      0.0164,      0.0117,\n",
       "             -0.0058,     -0.0007,      0.0266,      0.0088,     -0.0317,      0.0189,     -0.0086,      0.0342,\n",
       "             -0.0152,     -0.0060,      0.0011,     -0.0184,     -0.0192,     -0.0364,      0.0040,      0.0412,\n",
       "              0.0138,     -0.0073,      0.0039,      0.0024,     -0.0216,     -0.0145,     -0.0002,      0.0006,\n",
       "             -0.0168,      0.0231,      0.0097,     -0.0082,      0.0012,     -0.0210,     -0.0067,     -0.0141,\n",
       "              0.0034,     -0.0078,     -0.0147,     -0.0213,      0.0054,      0.0040,     -0.0046,     -0.0155,\n",
       "             -0.0076,      0.0122,     -0.0048,     -0.0089,     -0.0103,      0.0073,     -0.0060,      0.0024,\n",
       "              0.0211,     -0.0086,     -0.0116,     -0.0273,     -0.0206,      0.0045,     -0.0186,     -0.0116,\n",
       "              0.0005,     -0.0062,     -0.0244,     -0.0071,     -0.0144,     -0.0024,      0.0216,      0.0229,\n",
       "             -0.0137,      0.0078,     -0.0086,      0.0242,      0.0038,      0.0007,      0.0161,      0.0259,\n",
       "              0.0181,      0.0293,      0.0017,     -0.0030,      0.0320,     -0.0140,      0.0274,     -0.0189,\n",
       "              0.0026,      0.0135,     -0.0135,     -0.0149,     -0.0109,      0.0186,      0.0043,     -0.0167,\n",
       "             -0.0126,     -0.0455,     -0.0051,     -0.0251,      0.0068,     -0.0179,     -0.0008,     -0.0063],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Linear' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfc\u001b[39m.\u001b[39;49mparams\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "model.fc.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
       "         [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
       "         [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
       "         ...,\n",
       "         [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
       "         [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
       "         [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([    -0.0026,      0.0030,      0.0007,     -0.0269,      0.0064,      0.0133,     -0.0112,      0.0206,\n",
       "             -0.0036,     -0.0123,     -0.0126,     -0.0072,     -0.0193,     -0.0250,     -0.0119,     -0.0083,\n",
       "             -0.0096,     -0.0167,      0.0092,     -0.0154,      0.0071,      0.0307,      0.0132,     -0.0078,\n",
       "              0.0047,      0.0112,      0.0159,     -0.0167,     -0.0010,     -0.0037,      0.0065,     -0.0120,\n",
       "              0.0090,     -0.0008,      0.0089,     -0.0263,     -0.0146,      0.0029,      0.0030,     -0.0191,\n",
       "             -0.0048,      0.0138,      0.0099,     -0.0184,      0.0197,      0.0017,      0.0124,     -0.0056,\n",
       "             -0.0106,      0.0004,      0.0043,     -0.0133,      0.0207,      0.0170,      0.0028,      0.0007,\n",
       "              0.0132,      0.0032,      0.0105,      0.0165,      0.0009,      0.0039,     -0.0057,      0.0194,\n",
       "              0.0075,      0.0134,     -0.0132,     -0.0100,      0.0072,     -0.0023,     -0.0189,      0.0125,\n",
       "              0.0020,      0.0074,     -0.0097,      0.0202,      0.0077,      0.0185,      0.0157,      0.0186,\n",
       "             -0.0069,      0.0171,      0.0091,     -0.0389,     -0.0241,     -0.0069,     -0.0116,      0.0079,\n",
       "              0.0018,      0.0285,     -0.0194,     -0.0163,      0.0105,     -0.0130,     -0.0084,     -0.0292,\n",
       "             -0.0025,     -0.0087,     -0.0164,     -0.0093,     -0.0159,     -0.0263,     -0.0011,      0.0226,\n",
       "              0.0021,     -0.0232,     -0.0141,     -0.0056,     -0.0201,     -0.0303,     -0.0496,      0.0233,\n",
       "              0.0150,     -0.0078,     -0.0039,     -0.0376,     -0.0242,     -0.0102,     -0.0077,     -0.0041,\n",
       "             -0.0030,     -0.0062,     -0.0121,     -0.0070,     -0.0039,     -0.0170,     -0.0246,      0.0055,\n",
       "             -0.0083,     -0.0071,     -0.0240,     -0.0064,      0.0007,      0.0053,     -0.0222,     -0.0270,\n",
       "             -0.0180,     -0.0164,      0.0021,     -0.0161,     -0.0161,      0.0066,     -0.0200,      0.0064,\n",
       "             -0.0126,     -0.0076,      0.0114,     -0.0451,     -0.0092,     -0.0156,     -0.0136,     -0.0014,\n",
       "             -0.0195,      0.0207,     -0.0105,      0.0063,      0.0083,     -0.0108,     -0.0189,      0.0059,\n",
       "             -0.0020,      0.0324,      0.0406,     -0.0000,      0.0109,     -0.0165,     -0.0005,     -0.0229,\n",
       "              0.0046,     -0.0048,      0.0102,      0.0180,      0.0048,      0.0062,      0.0144,     -0.0121,\n",
       "             -0.0087,      0.0019,      0.0147,      0.0125,      0.0071,     -0.0042,      0.0120,     -0.0202,\n",
       "              0.0099,      0.0140,     -0.0010,      0.0057,      0.0014,      0.0006,     -0.0006,      0.0244,\n",
       "              0.0231,     -0.0146,      0.0112,      0.0346,      0.0169,      0.0043,     -0.0256,      0.0123,\n",
       "             -0.0258,      0.0085,      0.0204,      0.0226,      0.0230,      0.0088,     -0.0139,      0.0039,\n",
       "             -0.0093,      0.0232,     -0.0149,      0.0069,      0.0050,     -0.0173,      0.0010,     -0.0102,\n",
       "             -0.0097,      0.0345,      0.0061,      0.0116,     -0.0205,     -0.0220,      0.0053,      0.0341,\n",
       "             -0.0058,      0.0294,     -0.0088,     -0.0053,     -0.0191,      0.0304,      0.0184,     -0.0212,\n",
       "              0.0184,      0.0138,      0.0178,     -0.0045,      0.0359,      0.0218,      0.0109,      0.0403,\n",
       "             -0.0020,     -0.0030,      0.0093,     -0.0163,      0.0010,      0.0187,     -0.0166,      0.0150,\n",
       "             -0.0037,     -0.0077,     -0.0000,      0.0040,     -0.0096,     -0.0168,      0.0001,     -0.0064,\n",
       "              0.0083,      0.0048,     -0.0011,      0.0049,      0.0173,      0.0039,     -0.0078,      0.0161,\n",
       "              0.0099,     -0.0101,      0.0209,     -0.0063,     -0.0231,      0.0012,      0.0225,     -0.0067,\n",
       "              0.0183,      0.0146,     -0.0117,     -0.0143,      0.0130,     -0.0097,     -0.0062,      0.0132,\n",
       "              0.0068,      0.0464,     -0.0280,     -0.0151,      0.0287,      0.0092,     -0.0054,     -0.0060,\n",
       "             -0.0072,     -0.0092,      0.0019,     -0.0031,     -0.0084,     -0.0168,      0.0041,      0.0062,\n",
       "             -0.0012,     -0.0129,      0.0036,      0.0110,     -0.0133,      0.0026,      0.0090,      0.0065,\n",
       "             -0.0120,      0.0171,      0.0179,     -0.0106,     -0.0270,     -0.0136,     -0.0097,     -0.0021,\n",
       "              0.0354,      0.0184,      0.0267,     -0.0011,     -0.0034,     -0.0049,      0.0134,     -0.0139,\n",
       "             -0.0196,     -0.0233,     -0.0378,     -0.0146,     -0.0213,     -0.0310,     -0.0308,      0.0019,\n",
       "              0.0029,     -0.0212,      0.0104,     -0.0113,     -0.0043,      0.0226,     -0.0129,     -0.0110,\n",
       "              0.0123,     -0.0201,     -0.0218,     -0.0068,     -0.0105,     -0.0263,     -0.0100,     -0.0130,\n",
       "             -0.0025,     -0.0071,      0.0180,     -0.0064,      0.0079,     -0.0123,      0.0098,      0.0027,\n",
       "             -0.0215,      0.0028,     -0.0092,     -0.0175,     -0.0017,     -0.0146,      0.0044,      0.0344,\n",
       "              0.0127,      0.0309,      0.0013,     -0.0001,     -0.0023,     -0.0038,     -0.0111,      0.0172,\n",
       "             -0.0068,     -0.0001,     -0.0089,     -0.0163,     -0.0045,      0.0113,     -0.0016,     -0.0088,\n",
       "             -0.0049,      0.0046,     -0.0109,      0.0129,     -0.0067,     -0.0026,      0.0028,      0.0112,\n",
       "             -0.0221,     -0.0039,     -0.0066,     -0.0188,     -0.0217,     -0.0007,     -0.0273,      0.0050,\n",
       "             -0.0207,     -0.0341,     -0.0224,     -0.0167,     -0.0279,     -0.0099,      0.0055,      0.0160,\n",
       "             -0.0149,      0.0035,      0.0090,     -0.0084,     -0.0375,      0.0207,     -0.0059,      0.0092,\n",
       "             -0.0203,     -0.0073,     -0.0017,     -0.0014,      0.0032,      0.0292,      0.0125,     -0.0201,\n",
       "              0.0212,     -0.0253,      0.0318,     -0.0011,     -0.0104,     -0.0234,      0.0146,      0.0212,\n",
       "              0.0165,     -0.0032,     -0.0204,     -0.0370,     -0.0087,      0.0055,      0.0011,      0.0022,\n",
       "              0.0030,     -0.0001,      0.0006,     -0.0037,      0.0054,     -0.0248,      0.0093,      0.0096,\n",
       "              0.0092,      0.0091,      0.0075,     -0.0119,      0.0214,      0.0279,      0.0147,     -0.0025,\n",
       "              0.0289,      0.0134,      0.0017,      0.0025,     -0.0213,     -0.0008,      0.0042,      0.0086,\n",
       "              0.0187,      0.0086,     -0.0088,      0.0175,     -0.0137,      0.0022,      0.0108,      0.0029,\n",
       "              0.0310,      0.0085,     -0.0142,     -0.0022,      0.0187,     -0.0129,      0.0404,     -0.0008,\n",
       "              0.0019,      0.0073,     -0.0265,     -0.0176,     -0.0241,      0.0030,     -0.0159,      0.0016,\n",
       "              0.0111,      0.0146,     -0.0082,     -0.0077,     -0.0185,     -0.0090,      0.0041,      0.0445,\n",
       "             -0.0237,     -0.0053,     -0.0195,      0.0033,      0.0055,     -0.0050,      0.0077,     -0.0033,\n",
       "             -0.0026,     -0.0111,      0.0239,      0.0181,     -0.0181,      0.0052,     -0.0136,      0.0194,\n",
       "              0.0110,      0.0269,     -0.0067,     -0.0009,     -0.0035,     -0.0197,     -0.0185,     -0.0008,\n",
       "             -0.0164,     -0.0159,     -0.0137,      0.0175,     -0.0011,     -0.0063,     -0.0111,      0.0132,\n",
       "             -0.0235,      0.0003,     -0.0004,      0.0238,     -0.0027,     -0.0222,      0.0134,      0.0104,\n",
       "             -0.0235,      0.0168,      0.0044,     -0.0132,     -0.0029,      0.0054,      0.0020,     -0.0007,\n",
       "             -0.0004,      0.0178,      0.0184,      0.0285,     -0.0338,     -0.0108,     -0.0124,     -0.0019,\n",
       "             -0.0016,      0.0173,     -0.0040,     -0.0152,     -0.0108,      0.0054,     -0.0003,      0.0003,\n",
       "             -0.0102,     -0.0040,     -0.0035,      0.0042,     -0.0015,      0.0132,      0.0076,      0.0002,\n",
       "              0.0030,      0.0086,     -0.0112,      0.0385,     -0.0262,     -0.0203,     -0.0064,      0.0219,\n",
       "             -0.0073,      0.0053,     -0.0117,      0.0084,      0.0029,     -0.0047,      0.0231,     -0.0076,\n",
       "              0.0028,     -0.0117,     -0.0044,      0.0118,     -0.0018,     -0.0123,     -0.0021,      0.0121,\n",
       "              0.0068,     -0.0002,     -0.0251,      0.0127,      0.0161,      0.0081,      0.0014,      0.0030,\n",
       "             -0.0141,      0.0198,     -0.0009,     -0.0184,      0.0078,      0.0153,     -0.0128,     -0.0090,\n",
       "              0.0180,      0.0249,      0.0178,      0.0089,     -0.0094,     -0.0014,      0.0129,      0.0090,\n",
       "              0.0167,     -0.0054,      0.0275,     -0.0318,     -0.0133,      0.0056,     -0.0133,     -0.0192,\n",
       "             -0.0133,      0.0042,      0.0302,     -0.0082,      0.0083,      0.0190,      0.0106,      0.0313,\n",
       "              0.0193,      0.0034,      0.0197,      0.0023,     -0.0196,      0.0201,     -0.0114,     -0.0076,\n",
       "              0.0151,     -0.0030,     -0.0093,     -0.0042,      0.0023,     -0.0051,     -0.0145,     -0.0277,\n",
       "             -0.0387,      0.0054,      0.0135,     -0.0013,      0.0375,      0.0015,      0.0240,     -0.0206,\n",
       "              0.0098,      0.0104,      0.0386,     -0.0119,     -0.0217,      0.0084,      0.0147,      0.0226,\n",
       "             -0.0038,      0.0156,     -0.0094,      0.0054,      0.0196,     -0.0112,      0.0152,      0.0055,\n",
       "              0.0230,      0.0293,     -0.0015,      0.0066,     -0.0319,     -0.0105,     -0.0045,      0.0319,\n",
       "              0.0137,      0.0136,      0.0071,     -0.0168,     -0.0255,      0.0198,      0.0267,     -0.0047,\n",
       "              0.0177,      0.0325,      0.0146,      0.0261,      0.0113,     -0.0022,      0.0352,     -0.0119,\n",
       "             -0.0187,     -0.0055,     -0.0071,     -0.0053,      0.0076,     -0.0185,     -0.0169,      0.0101,\n",
       "              0.0130,     -0.0018,      0.0007,     -0.0112,      0.0136,     -0.0182,     -0.0265,      0.0061,\n",
       "              0.0397,     -0.0143,      0.0180,     -0.0140,     -0.0188,     -0.0118,     -0.0164,      0.0090,\n",
       "             -0.0073,      0.0175,     -0.0007,      0.0102,      0.0238,      0.0081,      0.0080,      0.0119,\n",
       "              0.0062,     -0.0246,      0.0295,     -0.0142,     -0.0187,     -0.0141,      0.0080,     -0.0211,\n",
       "             -0.0276,     -0.0036,      0.0016,      0.0095,      0.0183,     -0.0024,      0.0012,     -0.0006,\n",
       "              0.0088,      0.0028,      0.0007,      0.0159,     -0.0070,      0.0025,     -0.0179,      0.0085,\n",
       "              0.0043,      0.0245,      0.0037,      0.0103,     -0.0134,      0.0005,      0.0103,      0.0152,\n",
       "              0.0399,     -0.0081,      0.0138,     -0.0066,      0.0066,     -0.0315,      0.0247,      0.0034,\n",
       "              0.0210,      0.0194,     -0.0209,      0.0071,      0.0104,      0.0000,     -0.0192,      0.0063,\n",
       "             -0.0002,      0.0089,     -0.0048,     -0.0145,      0.0032,      0.0073,      0.0207,     -0.0005,\n",
       "              0.0188,      0.0391,     -0.0271,     -0.0183,     -0.0199,     -0.0094,      0.0042,      0.0054,\n",
       "             -0.0047,     -0.0130,     -0.0245,     -0.0089,     -0.0146,      0.0026,     -0.0308,      0.0112,\n",
       "             -0.0068,     -0.0076,     -0.0093,      0.0015,     -0.0023,      0.0004,     -0.0108,      0.0088,\n",
       "             -0.0210,     -0.0080,     -0.0108,     -0.0065,     -0.0021,      0.0223,     -0.0192,      0.0041,\n",
       "              0.0008,      0.0017,     -0.0175,     -0.0132,     -0.0074,     -0.0018,      0.0013,     -0.0067,\n",
       "             -0.0071,      0.0063,     -0.0181,     -0.0095,     -0.0209,      0.0090,      0.0213,      0.0170,\n",
       "              0.0210,      0.0088,     -0.0098,     -0.0223,      0.0243,     -0.0112,     -0.0076,      0.0061,\n",
       "             -0.0207,     -0.0163,      0.0265,     -0.0148,      0.0187,      0.0255,      0.0241,      0.0048,\n",
       "              0.0233,      0.0004,      0.0252,      0.0171,      0.0178,      0.0247,      0.0090,      0.0024,\n",
       "              0.0261,     -0.0141,     -0.0005,      0.0009,      0.0212,      0.0048,     -0.0305,     -0.0075,\n",
       "             -0.0337,     -0.0289,      0.0157,      0.0062,     -0.0109,      0.0195,     -0.0162,      0.0090,\n",
       "              0.0092,     -0.0029,     -0.0109,      0.0108,      0.0488,     -0.0020,      0.0268,     -0.0049,\n",
       "              0.0135,     -0.0145,     -0.0276,      0.0061,      0.0048,      0.0022,     -0.0376,      0.0308,\n",
       "              0.0200,      0.0185,      0.0030,      0.0094,      0.0005,      0.0616,     -0.0086,     -0.0269,\n",
       "              0.0064,      0.0078,      0.0132,     -0.0017,      0.0209,      0.0099,      0.0088,      0.0148,\n",
       "              0.0033,      0.0036,      0.0287,     -0.0221,     -0.0072,      0.0104,      0.0164,      0.0117,\n",
       "             -0.0058,     -0.0007,      0.0266,      0.0088,     -0.0317,      0.0189,     -0.0086,      0.0342,\n",
       "             -0.0152,     -0.0060,      0.0011,     -0.0184,     -0.0192,     -0.0364,      0.0040,      0.0412,\n",
       "              0.0138,     -0.0073,      0.0039,      0.0024,     -0.0216,     -0.0145,     -0.0002,      0.0006,\n",
       "             -0.0168,      0.0231,      0.0097,     -0.0082,      0.0012,     -0.0210,     -0.0067,     -0.0141,\n",
       "              0.0034,     -0.0078,     -0.0147,     -0.0213,      0.0054,      0.0040,     -0.0046,     -0.0155,\n",
       "             -0.0076,      0.0122,     -0.0048,     -0.0089,     -0.0103,      0.0073,     -0.0060,      0.0024,\n",
       "              0.0211,     -0.0086,     -0.0116,     -0.0273,     -0.0206,      0.0045,     -0.0186,     -0.0116,\n",
       "              0.0005,     -0.0062,     -0.0244,     -0.0071,     -0.0144,     -0.0024,      0.0216,      0.0229,\n",
       "             -0.0137,      0.0078,     -0.0086,      0.0242,      0.0038,      0.0007,      0.0161,      0.0259,\n",
       "              0.0181,      0.0293,      0.0017,     -0.0030,      0.0320,     -0.0140,      0.0274,     -0.0189,\n",
       "              0.0026,      0.0135,     -0.0135,     -0.0149,     -0.0109,      0.0186,      0.0043,     -0.0167,\n",
       "             -0.0126,     -0.0455,     -0.0051,     -0.0251,      0.0068,     -0.0179,     -0.0008,     -0.0063],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "params = list(model.fc.parameters())\n",
    "params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
       "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
       "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
       "        ...,\n",
       "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
       "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
       "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "params[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
       "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
       "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
       "        ...,\n",
       "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
       "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
       "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "params = list(model.fc.parameters())\n",
    "params[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0185, -0.0705, -0.0518,  ..., -0.0390,  0.1735, -0.0410],\n",
      "        [-0.0818, -0.0944,  0.0174,  ...,  0.2028, -0.0248,  0.0372],\n",
      "        [-0.0332, -0.0566, -0.0242,  ..., -0.0344, -0.0227,  0.0197],\n",
      "        ...,\n",
      "        [-0.0103,  0.0033, -0.0359,  ..., -0.0279, -0.0115,  0.0128],\n",
      "        [-0.0359, -0.0353, -0.0296,  ..., -0.0330, -0.0110, -0.0513],\n",
      "        [ 0.0021, -0.0248, -0.0829,  ...,  0.0417, -0.0500,  0.0663]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "params = list(model.fc.parameters())\n",
    "print(params[0])\n",
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The parameter 'num_classes' expected value 1000 but got 10 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mresnet18(weights\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mIMAGENET1K_V1\u001b[39;49m\u001b[39m\"\u001b[39;49m, num_classes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(model\u001b[39m.\u001b[39mfc\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(params[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m{\u001b[39;00msequence_to_str(\u001b[39mtuple\u001b[39m(keyword_only_kwargs\u001b[39m.\u001b[39mkeys()),\u001b[39m \u001b[39mseparate_last\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mand \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m as positional \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[39m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[39mreturn\u001b[39;00m builder(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:705\u001b[0m, in \u001b[0;36mresnet18\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"ResNet-18 from `Deep Residual Learning for Image Recognition <https://arxiv.org/abs/1512.03385>`__.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \n\u001b[1;32m    687\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[39m    :members:\u001b[39;00m\n\u001b[1;32m    702\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    703\u001b[0m weights \u001b[39m=\u001b[39m ResNet18_Weights\u001b[39m.\u001b[39mverify(weights)\n\u001b[0;32m--> 705\u001b[0m \u001b[39mreturn\u001b[39;00m _resnet(BasicBlock, [\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m], weights, progress, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:296\u001b[0m, in \u001b[0;36m_resnet\u001b[0;34m(block, layers, weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resnet\u001b[39m(\n\u001b[1;32m    289\u001b[0m     block: Type[Union[BasicBlock, Bottleneck]],\n\u001b[1;32m    290\u001b[0m     layers: List[\u001b[39mint\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    294\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResNet:\n\u001b[1;32m    295\u001b[0m     \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m         _ovewrite_named_param(kwargs, \u001b[39m\"\u001b[39;49m\u001b[39mnum_classes\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mlen\u001b[39;49m(weights\u001b[39m.\u001b[39;49mmeta[\u001b[39m\"\u001b[39;49m\u001b[39mcategories\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m    298\u001b[0m     model \u001b[39m=\u001b[39m ResNet(block, layers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    300\u001b[0m     \u001b[39mif\u001b[39;00m weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/_utils.py:238\u001b[0m, in \u001b[0;36m_ovewrite_named_param\u001b[0;34m(kwargs, param, new_value)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m param \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    237\u001b[0m     \u001b[39mif\u001b[39;00m kwargs[param] \u001b[39m!=\u001b[39m new_value:\n\u001b[0;32m--> 238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe parameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m expected value \u001b[39m\u001b[39m{\u001b[39;00mnew_value\u001b[39m}\u001b[39;00m\u001b[39m but got \u001b[39m\u001b[39m{\u001b[39;00mkwargs[param]\u001b[39m}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     kwargs[param] \u001b[39m=\u001b[39m new_value\n",
      "\u001b[0;31mValueError\u001b[0m: The parameter 'num_classes' expected value 1000 but got 10 instead."
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\", num_classes=10)\n",
    "\n",
    "params = list(model.fc.parameters())\n",
    "print(params[0])\n",
    "params[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mresnet18(weights\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIMAGENET1K_V1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m Linear(in_features\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, out_features\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Linear' is not defined"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x178864ac0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0171, -0.0432,  0.0253,  ..., -0.0237, -0.0168, -0.0085],\n",
       "         [ 0.0425, -0.0218,  0.0109,  ...,  0.0075, -0.0185, -0.0160],\n",
       "         [-0.0260,  0.0099, -0.0143,  ...,  0.0331,  0.0127, -0.0039],\n",
       "         ...,\n",
       "         [-0.0023,  0.0315,  0.0395,  ...,  0.0030, -0.0348, -0.0373],\n",
       "         [ 0.0030,  0.0270,  0.0397,  ...,  0.0191,  0.0062, -0.0079],\n",
       "         [ 0.0080,  0.0401,  0.0224,  ...,  0.0193, -0.0369,  0.0291]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0080,  0.0376,  0.0237,  0.0279,  0.0177, -0.0375, -0.0344,  0.0234,  0.0192,  0.0065], requires_grad=True)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 3\u001b[0m validate(model, criterion, cifar10_loaders[\u001b[39m\"\u001b[39;49m\u001b[39meval\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32m/Users/citizen2/Documents/norm_research/experiment1.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     46\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     47\u001b[0m test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Documents/norm_research/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[32, 1, 28, 28] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "validate(model, criterion, cifar10_loaders[\"eval\"], \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
