{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Почему L1 (Lasso) регуляризация отбирает признаки?\n",
        "\n",
        "# L1 и L2 регуляризация\n",
        "\n",
        "Вспомним две базовые техники регуляризации.\n",
        "\n",
        "Для простоты будет разбирать все на основе линейной регрессии со\n",
        "среднеквадратичной ошибкой.\n",
        "\n",
        "Функция потерь с L1 регуляризацией:\n",
        "\n",
        "$$ \\text{Loss}+ L_1 = \\frac{1}{2n} ||y - Xw||_{2}^{2} + \\alpha ||w||_1 $$\n",
        "\n",
        "$$ ||w||_1 = |w_1| + |w_2| + \\ldots $$\n",
        "\n",
        "И с L2 регуляризацией:\n",
        "\n",
        "$$ \\text{Loss} + L_2 = \\frac{1}{2n} ||y - Xw||_{2}^{2} + \\alpha ||w||_{2}^{2} $$\n",
        "\n",
        "$$ ||w||_{2}^{2} = w_{1}^2 + w_{2}^2 + \\ldots $$\n",
        "\n",
        "L1 обычно рекомендуют использовать в ситуации, когда:\n",
        "\n",
        "-   в датасете огромное количество признаков\n",
        "-   заранее известно, что часть признаков неинформативна\n",
        "-   вычислительные ресурсы ограничены (нужно очень быстро получать ответ\n",
        "    или данных очень много)\n",
        "\n",
        "В процессе оптимизации L1 техника регуляризации полностью обнуляет часть\n",
        "признаков и в итоговой модели их можно не использовать.\n",
        "\n",
        "Ага, понятно… Стоп, а как обнуляет-то?\n",
        "\n",
        "Не особо очевидно. Будет разбираться.\n",
        "\n",
        "-   [ ] (или можно сразу прыгнуть к итогам → ссылка)\n",
        "\n",
        "# Спускаемся по градиенту\n",
        "\n",
        "Вообще, L1 просто константу добавляет/отнимает при градиентном спуске:\n",
        "\n",
        "$$ \\frac{\\partial L_1}{\\partial w_i} = \\alpha \\cdot \\text{sign}(w_i) $$\n",
        "\n",
        "$$w_i := w_i - \\lambda (\\frac{\\partial Loss}{\\partial w_i} +  \\alpha \\cdot \\text{sign}(w_i) ) $$\n",
        "\n",
        "Интуитивно, обнуляемые веса будут болтаться около ноля, но вот ровно в\n",
        "ноль попадать практически никогда не будут. Ну что ж, проверим интуицию\n",
        "на практике.\n",
        "\n",
        "## Генеририруем простенький датасет\n",
        "\n",
        "-   50 объектов\n",
        "-   10 признаков со случайным шумом\n",
        "-   3 признака с нулем\n",
        "-   1 признак с целевой переменной + немного шума\n",
        "-   последний признак константа с 1 (bias)"
      ],
      "id": "b89b06dc-7c34-4a43-a2d4-e3bb99ec8fd6"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %% Generate data\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "y = np.random.randn(50, 1)\n",
        "\n",
        "X = np.random.randn(50, 10)\n",
        "X = np.hstack((X, np.zeros((X.shape[0], 3))))\n",
        "X = np.hstack((X, y + 0.01 * np.random.randn(50, 1)))\n",
        "\n",
        "bias_column = np.ones((X.shape[0], 1))\n",
        "X = np.hstack((X, bias_column))\n",
        "print(\"Пример объекта: \")\n",
        "print(X[0])"
      ],
      "id": "2c53ae75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Реализуем градиентный спуск для L1"
      ],
      "id": "e17f450b-1df8-4982-bc68-8880bf9a5293"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "class LinearRegressionNaiveL1:\n",
        "    def __init__(self, learning_rate=1e-5, iterations=150, alpha=5):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.alpha = alpha  # regularization parameter\n",
        "        self.weights = np.random.randn(n_features, 1) * 0.001\n",
        "        self.bias = 0\n",
        "        self.loss_history = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for _ in range(self.iterations):\n",
        "            # Compute predictions\n",
        "            y_pred = self.predict(X)\n",
        "\n",
        "            # Compute gradients\n",
        "            d_l1 = self.alpha * np.sign(self.weights)\n",
        "            d_weights = (1/(2*n_samples)) * (X.T @ (y_pred - y))\n",
        "            d_bias = (1/(2*n_samples)) * np.sum(y_pred - y)\n",
        "\n",
        "            # Update weights and bias\n",
        "            self.weights -= self.learning_rate * (d_weights + d_l1)\n",
        "            self.bias -= self.learning_rate * d_bias\n",
        "            \n",
        "            mse = mean_squared_error(y, y_pred)            \n",
        "            self.loss_history.append(mse)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return X @ self.weights + self.bias"
      ],
      "id": "fb44f322"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LinearRegressionNaiveL1()\n",
        "model.fit(X, y)\n",
        "\n",
        "plt.plot(model.loss_history)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Loss Change Over Iterations')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.bar(range(len(model.weights)), model.weights.flatten())\n",
        "plt.xlabel('Feature Index')\n",
        "plt.ylabel('Weight Value')\n",
        "plt.title('Weights')\n",
        "plt.show()"
      ],
      "id": "f74a5b31"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Проверим, что в общеупотребительное решение, что работает\n",
        "\n",
        "От теории к практике. Как l1 и l2 работают в sklearn\n",
        "\n",
        "L1 регуляризация действительно полностью обнуляет часть весов модели, в\n",
        "отличии от L2 регуляризации.\n",
        "\n",
        "Мы можем это проверить,\n",
        "\n",
        "## сгенерировать простой датасет\n",
        "\n",
        "мы знаем как он себя ведет\n",
        "\n",
        "дальше будем работать только с ним\n",
        "\n",
        "``` python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
        "\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "X = np.random.randn(100, 10)\n",
        "y = X @ np.array([1.5, -2, 0, 0, 4.5, 0, 0, -3.5, 2, 0]) + np.random.randn(100)\n",
        "\n",
        "# Fit a linear regression model with L2 regularization\n",
        "lr = Ridge()\n",
        "lr.fit(X, y)\n",
        "weights_lr = lr.coef_\n",
        "\n",
        "# Fit a linear regression model with L1 regularization\n",
        "lasso = Lasso(alpha=0.1)\n",
        "lasso.fit(X, y)\n",
        "weights_lasso = lasso.coef_\n",
        "\n",
        "# Plot the weights for comparison\n",
        "# plt.figure(figsize=(10, 5))\n",
        "plt.plot(weights_lr, 'o-', label='Ridge Regression')\n",
        "plt.plot(weights_lasso, 's-', label='Lasso Regression')\n",
        "plt.xlabel('Feature index')\n",
        "plt.ylabel('Weight value')\n",
        "plt.title('Comparison of Weights (sklearn lib): Ridge Regression vs Lasso Regression')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Display the weights\n",
        "print(\"Ridge Regression Weights:\\n\", weights_lr)\n",
        "print(\"Lasso Regression Weights:\\n\", weights_lasso)\n",
        "```\n",
        "\n",
        "Рисунок 1\n",
        "\n",
        "# Л1 наивная реализация\n",
        "\n",
        "код\n",
        "\n",
        "не работает… почему?\n",
        "\n",
        "есть три нюанса: 1. коэффициэнты стратуеют с нуля (для линейной модели\n",
        "можно) 2. используется модификация градиентного спуска 3. ?\n",
        "\n",
        "# Л1 тру реализация\n",
        "\n",
        "дело не только в производной л1\n",
        "\n",
        "используется модификация градиентного спуска\n",
        "\n",
        "сам метод можно вывести через субградинеты, но это усложнение\n",
        "\n",
        "# Итоги\n",
        "\n",
        "Можно понять, что Л1 далеко не всегда является хорошей штукой\n",
        "\n",
        "# Прочие объяснения\n",
        "\n",
        "Обычно Л1 объясняют через вот эти графики, но мне оно не очевидно"
      ],
      "id": "ace914e7-ff22-46b0-a24f-da0597e60fec"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the original meshgrid\n",
        "x = np.linspace(-2, 2, 800)\n",
        "y = np.linspace(-2, 2, 800)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# L1 norm\n",
        "Z1 = np.abs(X) + np.abs(Y)\n",
        "\n",
        "# L2 norm\n",
        "Z2 = np.sqrt(X**2 + Y**2)\n",
        "\n",
        "# Rotation angle in radians\n",
        "theta = np.pi * 0.25 \n",
        "\n",
        "# Rotate the coordinates\n",
        "X_rot = X * np.cos(theta) - Y * np.sin(theta)\n",
        "Y_rot = X * np.sin(theta) + Y * np.cos(theta)\n",
        "\n",
        "# MSE with target (a, b)\n",
        "a, b = 1, 0\n",
        "Z_mse_rot = (X_rot - a)**2 + (2*Y_rot - b)**2\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# L1 contour plot\n",
        "ax1.contour(X, Y, Z1, levels=10)\n",
        "ax1.set_title('L1 Norm Contour Plot')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.axhline(0, color='black', linewidth=0.5)\n",
        "ax1.axvline(0, color='black', linewidth=0.5)\n",
        "ax1.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# L2 contour plot\n",
        "ax2.contour(X, Y, Z2, levels=10)\n",
        "ax2.set_title('L2 Norm Contour Plot')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.axhline(0, color='black', linewidth=0.5)\n",
        "ax2.axvline(0, color='black', linewidth=0.5)\n",
        "ax2.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# MSE contour plot\n",
        "ax3.contour(X, Y, Z_mse_rot, levels=10)\n",
        "ax3.set_title('MSE Contour Plot')\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('y')\n",
        "ax3.axhline(0, color='black', linewidth=0.5)\n",
        "ax3.axvline(0, color='black', linewidth=0.5)\n",
        "ax3.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "id": "b2b198ea"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# L1 norm contour plot\n",
        "ax.contour(X, Y, Z1, levels=[1], colors='b', label='L1 Norm')\n",
        "\n",
        "# L2 norm contour plot\n",
        "ax.contour(X, Y, Z2, levels=[1], colors='g', label='L2 Norm')\n",
        "\n",
        "# MSE contour plot\n",
        "ax.contour(X, Y, Z_mse_rot, levels=[1], colors='r', label='MSE')\n",
        "\n",
        "ax.set_title('Contour Plots of L1, L2 Norms, and MSE')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.axhline(0, color='black', linewidth=0.5)\n",
        "ax.axvline(0, color='black', linewidth=0.5)\n",
        "ax.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "acfc3a3e"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate the original meshgrid\n",
        "x = np.linspace(-2, 2, 800)\n",
        "y = np.linspace(-2, 2, 800)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "# L1 norm\n",
        "Z1 = np.abs(X) + np.abs(Y)\n",
        "\n",
        "# L2 norm\n",
        "Z2 = np.sqrt(X**2 + Y**2)\n",
        "\n",
        "# Rotation angle in radians\n",
        "theta = np.pi * 0.25 \n",
        "\n",
        "# Rotate the coordinates\n",
        "X_rot = X * np.cos(theta) - Y * np.sin(theta)\n",
        "Y_rot = X * np.sin(theta) + Y * np.cos(theta)\n",
        "\n",
        "# MSE with target (a, b)\n",
        "a, b = 1, 0\n",
        "Z_mse_rot = (X_rot - a)**2 + (4*Y_rot - b)**2\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# L1 contour plot\n",
        "ax1.contour(X, Y, Z1, levels=10)\n",
        "ax1.set_title('L1 Norm Contour Plot')\n",
        "ax1.set_xlabel('x')\n",
        "ax1.set_ylabel('y')\n",
        "ax1.axhline(0, color='black', linewidth=0.5)\n",
        "ax1.axvline(0, color='black', linewidth=0.5)\n",
        "ax1.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# L2 contour plot\n",
        "ax2.contour(X, Y, Z2, levels=10)\n",
        "ax2.set_title('L2 Norm Contour Plot')\n",
        "ax2.set_xlabel('x')\n",
        "ax2.set_ylabel('y')\n",
        "ax2.axhline(0, color='black', linewidth=0.5)\n",
        "ax2.axvline(0, color='black', linewidth=0.5)\n",
        "ax2.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "# MSE contour plot\n",
        "ax3.contour(X, Y, Z_mse_rot, levels=10)\n",
        "ax3.set_title('MSE Contour Plot')\n",
        "ax3.set_xlabel('x')\n",
        "ax3.set_ylabel('y')\n",
        "ax3.axhline(0, color='black', linewidth=0.5)\n",
        "ax3.axvline(0, color='black', linewidth=0.5)\n",
        "ax3.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.show()"
      ],
      "id": "6ac5d6e2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# L1 norm contour plot\n",
        "ax.contour(X, Y, Z1, levels=[1], colors='b', label='L1 Norm')\n",
        "\n",
        "# L2 norm contour plot\n",
        "ax.contour(X, Y, Z2, levels=[1], colors='g', label='L2 Norm')\n",
        "\n",
        "# MSE contour plot\n",
        "ax.contour(X, Y, Z_mse_rot, levels=[1], colors='r', label='MSE')\n",
        "\n",
        "ax.set_title('Contour Plots of L1, L2 Norms, and MSE')\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.axhline(0, color='black', linewidth=0.5)\n",
        "ax.axvline(0, color='black', linewidth=0.5)\n",
        "ax.grid(color='gray', linestyle='--', linewidth=0.5)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "d08a27e5"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/Users/citizen2/Documents/ml_basics/.venv/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  }
}