{
  "hash": "af8d48fe0d88b1f2ece08b12552bcb1b",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Под капотом L1 регуляризации\"\nsubtitle: \"Почему она отбирает признаки?\"\ndate: \"2024-07-01\"\n# categories: [news, code, analysis]\n# image: \"l1_fig.jpg\"\n\n\nlang: ru\ntoc: true\nformat:\n  # ipynb: default\n  html:\n    code-fold: true\njupyter: python3\n# execute:\n#   eval: true\n#   freeze: auto\n---\n\n\n# Введение\n\nL1 регуляризация умеет отбирать признаки. Это ее свойство почти повсеместно объясняют с помощью статистических рассуждений и варианта вот этой иллюстрации от создателей алгоритма:\n\n![Image from Elements of Statistical Learning by Hastie, Tibshirani, and Friedman](l1_fig.png)\n\nРазглядывая эту картинку, у меня и правда возникло смутное чувство интуитивного понимания. Но вот когда я попытался объяснить суть алголритма знакомому, эта интуиция куда-то улетучилась.\n\nПредлагаю вместе со мной разобраться, как L1 действительно отбирает признаки.\n\nДля наглядности мы будем регуляризовывать линейную регрессию со среднеквадратичной ошибкой (lasso regression).\n\nМои рассуждения можно пропустить и сразу [прыгнуть до ключевой идеи](#sec-bottom-line).\n\n# Определяем L1\n\nИтак, чтобы регуляризовать линейную регрессию, мы просто добавляем к ее ошибке штраф, который зависит от абсолютного размера весов:\n\n$$ \\text{MSE Loss}+ L_1 = \\frac{1}{2n} ||\\mathbf{Xw} - \\mathbf{y}||_{2}^{2} + \\alpha ||\\mathbf{w}||_1 $$\n\n$$ ||\\mathbf{w}||_1 = |w_1| + |w_2| + \\ldots $$\n\nДля нахождения оптимальных весов нам, как обычно, потребуются градиенты:\n\n$$ \\nabla_w \\text{MSE Loss} = \\frac{1}{n} \\mathbf{X}^T (\\mathbf{Xw} - \\mathbf{y}) $$\n\n$$ \\mathbf{\\nabla_w} L_1 = \\alpha \\cdot \\text{sign}(\\mathbf{w}) $$\n\n\\begin{equation}\n\\text{sign}(w_i) = \\begin{cases} \n-1 & \\text{if } w_i < 0 \\\\\n0 & \\text{if } w_i = 0 \\\\\n1 & \\text{if } w_i > 0 \n\\end{cases}\n\\end{equation}\n\nОкей, а как это оптимизировать? Вообще, у L1 разрыв производной в нуле и, формально, градиентный спуск здесь применять нельзя. А вдруг это не критично? Давайте порпобуем обычный градиентный спуск.\n\n\n# Спускаемся по градиенту\n\nСначала сгенерируем простенький датасет:\n\n* 50 объектов\n* 1 релевантный признак\n* 4 признака со случайным шумом\n\n::: {#b077dca0 .cell .column-body-outset execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_regression\n\nsns.set()\nnp.set_printoptions(suppress=True)\n\nnp.random.seed(42)\n\n# Generate the data\nX, y = make_regression(n_samples=50, n_features=5, n_informative=1, noise=0.01, bias=1)\ny = y.reshape(-1, 1)\n\n# Plot correlation plots\ndata = pd.DataFrame(X, columns=[f'Feature {i}' for i in range(X.shape[1])])\ndata['Target'] = y\n\nax = sns.pairplot(data, y_vars='Target', x_vars=data.columns[:-1], kind='reg')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_explained_files/figure-html/cell-2-output-1.png){width=1179 height=238}\n:::\n:::\n\n\nДалее набросаем саму модель. Ее веса будем обновлять следующим образом:\n\n$$w_i := w_i - \\lambda (\\frac{\\partial \\text{MSE Loss}}{\\partial w_i} +  \\alpha \\cdot \\text{sign}(w_i) ) $$\n\n::: {#69b45221 .cell execution_count=2}\n``` {.python .cell-code code-fold=\"false\"}\nfrom sklearn.metrics import mean_squared_error\n\nclass LinearRegressionNaiveL1:\n    def __init__(self, learning_rate, epochs, alpha, n_features):\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.alpha = alpha  # regularization parameter\n        # We can init weights with zeros, because we calculated the gradient analytically\n        self.weights = np.zeros((n_features,1))\n        self.bias = 0\n        self.loss_history = []\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n\n        for _ in range(self.epochs):\n            y_pred = self.predict(X)\n\n            # Compute gradients\n            d_l1 = self.alpha * np.sign(self.weights)\n            d_weights = (1/(2*n_samples)) * (X.T @ (y_pred - y))\n            d_bias = (1/(2*n_samples)) * np.sum(y_pred - y)\n\n            # Update weights and bias\n            self.weights -= self.learning_rate * (d_weights + d_l1)\n            self.bias -= self.learning_rate * d_bias\n            \n            mse = mean_squared_error(y, y_pred)            \n            self.loss_history.append(mse)\n\n    def predict(self, X):\n        return X @ self.weights + self.bias\n\n\nn_samples, n_features = X.shape\nlearning_rate = 0.1\nepochs = 200\nalpha = 0.5\n\nmodel = LinearRegressionNaiveL1(learning_rate=learning_rate, epochs=epochs, alpha=alpha, n_features=n_features)\nmodel.fit(X, y)\n```\n:::\n\n\n## Результаты обучения\n\nОбучение прошло без проблем, модель даже показывает приличные прогнозы.\n\n::: {layout-ncol=2 .column-page}\n\n::: {#e1fab61d .cell execution_count=3}\n``` {.python .cell-code}\nplt.plot(model.loss_history)\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss Change Over Iterations')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_explained_files/figure-html/cell-4-output-1.png){width=605 height=455}\n:::\n:::\n\n\n::: {#d484fd76 .cell execution_count=4}\n``` {.python .cell-code}\ny_pred = model.predict(X)\n\nplt.scatter(y, y_pred, color='blue', label='Predicted vs True')\nplt.plot([min(y), max(y)], [min(y), max(y)], color='red', linestyle='--', linewidth=2, label='Perfect Fit')\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs True Values')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_explained_files/figure-html/cell-5-output-1.png){width=606 height=455}\n:::\n:::\n\n\n:::\n\nАлгоритм правильно выцепил релевантный признак и дал ему большой вес. Однако, ни один вес в ноль не обратился:\n\n::: {#e59379ed .cell execution_count=5}\n``` {.python .cell-code}\nprint(model.weights.flatten())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[-0.0480011  -0.04580301  0.03685523 64.83100954 -0.05288193]\n```\n:::\n:::\n\n\nОкей, обычный градиентный спуск веса не обнуляет. Как быть?\n\n# Правильно спускаемся по градиенту {#sec-bottom-line}\n\nНужный алгоритм можно найти в теории оптимизации выпуклых функций. Как вариант, с помощью метода проксимального градиента наша задача решается. Но небанальные математические выкладки на самом деле приведут к весьма простой эвристике.\n\nИтак, готовы? \n\n:::{.callout-note}\n## Ключевая идея L1\n\nПосле обычного шага по градиенту\n\n$$w_i := w_i - \\lambda (\\frac{\\partial \\text{MSE Loss}}{\\partial w_i} +  \\alpha \\cdot \\text{sign}(w_i) ) $$\n\nПросто обнуляем все веса достаточно маленькие веса\n\n\\begin{equation}\nw_i := \\begin{cases} \nw_i & \\text{if } | w_i | < \\alpha \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\end{equation}\n\nИ тогда наш алгоритм будет отбирать признаки.\n\n:::\n\nВот, собственно, и все. По большому счету, нам не обязательно даже L1 штраф добавлять, чтобы срезать лишние признаки.\n\nПопробуем?\n\n::: {#0171be6e .cell execution_count=6}\n``` {.python .cell-code code-fold=\"false\"}\nclass LinearRegressionTrueL1:\n    def __init__(self, learning_rate, epochs, alpha, n_features):\n        self.learning_rate = learning_rate\n        self.epochs = epochs\n        self.alpha = alpha  # regularization parameter\n        # self.weights = np.random.randn(n_features, 1) * 0.001\n        self.weights = np.zeros((n_features,1))\n        self.bias = 0\n        self.loss_history = []\n    \n    def make_small_weights_zero(self, weights):\n        alpha_scaled = self.learning_rate * self.alpha\n        \n        clipped_step = np.sign(weights) * np.minimum(np.abs(weights), alpha_scaled)\n        \n        weights -= clipped_step\n\n        return weights\n\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n\n        for _ in range(self.epochs):\n            y_pred = self.predict(X)\n\n            # Compute gradients\n            d_l1 = self.alpha * np.sign(self.weights)\n            d_weights = (1/(2*n_samples)) * (X.T @ (y_pred - y))\n            d_bias = (1/(2*n_samples)) * np.sum(y_pred - y)\n\n            # Update weights and bias\n            self.weights -= self.learning_rate * (d_weights + d_l1)\n            self.weights = self.make_small_weights_zero(self.weights)\n            self.bias -= self.learning_rate * d_bias\n            \n            mse = mean_squared_error(y, y_pred)            \n            self.loss_history.append(mse)\n\n    def predict(self, X):\n        return X @ self.weights + self.bias\n\nmodel = LinearRegressionTrueL1(learning_rate=learning_rate, epochs=epochs, alpha=alpha, n_features=n_features)\nmodel.fit(X, y)\n```\n:::\n\n\n::: {layout-ncol=2 .column-page}\n\n::: {#892a5935 .cell execution_count=7}\n``` {.python .cell-code}\nplt.plot(model.loss_history)\nplt.xlabel('Iteration')\nplt.ylabel('Loss')\nplt.title('Loss Change Over Iterations')\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_explained_files/figure-html/cell-8-output-1.png){width=605 height=455}\n:::\n:::\n\n\n::: {#7f21afa3 .cell execution_count=8}\n``` {.python .cell-code}\ny_pred = model.predict(X)\n\nplt.scatter(y, y_pred, color='blue', label='Predicted vs True')\nplt.plot([min(y), max(y)], [min(y), max(y)], color='red', linestyle='--', linewidth=2, label='Perfect Fit')\nplt.xlabel('True Values')\nplt.ylabel('Predicted Values')\nplt.title('Predicted vs True Values')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](l1_explained_files/figure-html/cell-9-output-1.png){width=606 height=455}\n:::\n:::\n\n\n:::\n\nЧто у нас с весами новой модели?\n\n::: {#98265482 .cell execution_count=9}\n``` {.python .cell-code}\nprint(model.weights.flatten())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[ 0.          0.          0.         63.68450512  0.        ]\n```\n:::\n:::\n\n\nВсе веса, кроме одного у значимого признака, обратились в ноль. То есть, ура, у нас таки получилось отобрать признаки.\n\n\n# Итого\n\nМы разобрались, что под капотом у Л1 регуляризации довольно простая эвристика. Она работает на практике и действительно позволяет отбирать признаки.\n\nОчевидный нюанс: так как Л1 обнуляет любые веса меньше $\\alpha$, то она может отбросить значимые признаки, если они сильно отличаются по масштабу. Поэтому при использовании этой техники все признаки стоит нормализовывать.\n\nМенее очевидный нюанс: для отбора признаков L1 штраф можно заменить на любой другой и вообще обучаться на голой функции потерь. L1 штраф вводится, чтобы регуляризацией было проще управлять.\n\nВ заключение отмечу, что для линейных моделй L1 на практике чаще используется в связке с L2 регуляризацией (ElasticNet), а для оптимизации используеются еще несколько трюков, которые позволяют быстрее все посчитать. Но это уже выходит за рамки этой заметки.\n\n",
    "supporting": [
      "l1_explained_files"
    ],
    "filters": [],
    "includes": {}
  }
}